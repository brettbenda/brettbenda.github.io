Title,Abstract,VenueName,VenueType,Year,Abbreviation,Authors,PDFName,Link,Video
Detection of Scaled Hand Interactions in Virtual Reality: The Effects of Motion Direction and Task Complexity,"In virtual reality (VR), natural physical hand interaction allows users to interact with virtual content using physical gestures. While the most straightforward use of tracked hand motion maintains a one-to-one mapping between the physical and virtual world, some cases might benefit from changing this mapping through scaled or redirected interactions that modify the mapping between user’s physical movements and the magnitude of corresponding virtual movements. However, large deviations in interaction fidelity may potentially provide distractions or a loss of perceived realism. Therefore, it is important to know the extent to which remapping techniques can be applied to scaled interactions in VR without users detecting the difference. In this paper, we extend prior research on redirected hand techniques by investigating user perception of scaled hand movements and estimating detection thresholds for different types of hand motion in VR. We conducted two experiments with a two-alternative forced-choice (2AFC) design to estimate the detection thresholds of remapped interaction. The first experiment tested the perception of motion scaling for simple hand movements, and the second experiment involved more complex reaching motions in a cognitively demanding game scenario. We present estimated detection thresholds for scale values that can be applied to virtual hand movements without users noticing the difference. Our findings show that detection thresholds differ significantly based on the type of hand movement (horizontal, vertical, and depth).",IEEE Conference on Virtual Reality and 3D User Interfaces,Conference,2020,IEEEVR 2020,"Shaghayegh Esmaeili, Brett Benda, Eric D. Ragan",DetectionofScaledHandInteractionsinVirtualReality.pdf,https://doi.org/10.1109/VR46266.2020.00066,
Examining Fitts' and FFitts' Law Models for Children's Pointing Tasks on Touchscreens,"Fitts' law has accurately modeled both children's and adults' pointing movements, but it is not as precise for modeling movement to small targets. To address this issue, prior work presented FFitts' law, which is more exact than Fitts' law for modeling adults' finger input on touchscreens. Since children's touch interactions are more variable than adults, it is unclear if FFitts' law should be applied to children. We conducted a 2D target acquisition task with 54 children (ages 5-10) to examine if FFitts' law can accurately model children's touchscreen movement time. We found that Fitts' law using nominal target widths is more accurate, with a R2 value of 0.93, than FFitts' law for modeling children's finger input on touchscreens. Our work contributes new understanding of how to accurately predict children's finger touch performance on touchscreens.",International Conference on Advanced Visual Interfaces,Conference,2020,AVI 2020,"Julia Woodward, Isaac Wang, Jahelle Cato, Brett Benda, Jesse Smith, Lisa Anthony, Jaime Ruiz",FFittsLawForChildren.pdf,https://dl.acm.org/doi/abs/10.1145/3399715.3399844,
Determining Detection Thresholds for Fixed Positional Offsets for Virtual Hand Remapping in Virtual Reality,"Virtual reality commonly makes use of tracked hand interactions for user input. Interaction techniques sometimes alter the mapping between the real and virtual coordinate systems to modify interaction possibilities. This paper studies fixed positional offsets applied to the location of the virtual hand. We present a controlled experiment in which users' hands were subject to fixed positional offsets of varying magnitudes while completing target-touching tasks. The study provides estimations for detection thresholds for positional hand offsets in six directions relative to the real-world location of the hand and provides evidence performance using offset virtual hands can vary based on offset parameters. Significant differences in offset detection were identified based on offset direction, indicating that positional adjustments made to virtual hands should consider directionality when limiting techniques rather than just a constant value. Hand offsets kept within the threshold value resulted in comparable performance to unmodified hand registration, while offsets beyond the threshold resulted in larger completion times.",IEEE International Symposium on Mixed and Augmented Reality,Conference,2020,ISMAR 2020,"Brett Benda, Shaghayegh Esmaeili, Eric D. Ragan",DetectionOfOffsetHandPlacements.pdf,https://ieeexplore.ieee.org/abstract/document/9284804,
MMGatorAuth: A Novel Multimodal Dataset for Authentication Interactions in Gesture and Voice,"The future of smart environments is likely to involve both passive and active interactions on the part of users. Depending on what sensors are available in the space, users may make use of multimodal interaction modalities such as hand gestures or voice commands. There is a shortage of robust yet controlled multimodal interaction datasets for smart environment applications. One application domain of interest based on current state-of-the-art is authentication for sensitive or private tasks, such as banking and email. We present a novel, large multimodal dataset for authentication interactions in both gesture and voice, collected from 106 volunteers who each performed 10 examples of each of a set of hand gesture and spoken voice commands chosen from prior literature (10,600 gesture samples and 13,780 voice samples). We present the data collection method, raw data and common features extracted, and a case study illustrating how this dataset could be useful to researchers. Our goal is to provide a benchmark dataset for testing future multimodal authentication solutions, enabling comparison across approaches.",International Conference on Multimodal Interaction,Conference,2020,ICMI 2020,"Sarah Morrison-Smith, Aishat Aloba, Hangwei Lu, Brett Benda, Shaghayegh Esmaeili, Gianne Flores, Jesse Smith, Nikita Soni, Isaac Wang, Rejin Joy, Damon L. Woodard, Jaime Ruiz, Lisa Anthony",MMGatorAuth.pdf,https://dl.acm.org/doi/abs/10.1145/3382507.3418881,
InDrone: Visualizing Drone Flight Patterns for Indoor Building Inspection Tasks,"The use of drones or unmanned aerial vehicles for indoor building inspection tasks requires users to understand flight patterns (e.g., flight routes, camera focus points, target approach strategies) for maneuvering the aircraft. This study focuses on exploring the visual representation of human behaviors performing indoor building inspection flight operations using drones. An interactive 2D representation of drone flight spatial data-InDrone-was developed to characterize flight patterns during the inspection of indoor markers that were already defined in the inspection area and visualize potential maneuvering difficulties around those markers. This study evaluated InDrone via a user-centered assessment methodology that measured performance and usability ratings. Using visual flight patterns, users identified inspection markers and difficult-to-inspect building areas in 63% (STD = 48%) and 75% (STD = 35%) of the time on average, respectively. Overall, users reported high scores for the usability of InDrone during the flight pattern recognition tasks with a mean score of 77% (STD = 15%). This study contributes to the definition of visual affordances that support the communication of flight patterns for drone indoor building inspection tasks. The InDrone pilot system demonstrates the usefulness of visual affordances to explore drone flight spatial data for indoor building inspections.",International Conference on Construction Applications of Virtual Reality,Conference,2020,CONVR 2020,"Ricardo Eiris, Gilles Albeaino, Masoud Gheisari, William Benda, Randi Faris",InDrone.pdf,https://www.researchgate.net/publication/344442452_InDrone_Visualizing_Drone_Flight_Patterns_for_Indoor_Building_Inspection_Tasks,
InDrone: a 2D-based drone flight behavior visualization platform for indoor building inspection,, Smart and Sustainable Built Environment,Journal,2021,,"Ricardo Eiris, Gilles Albeaino, Masoud Gheisari, William Benda, Randi Faris",InDroneSASBE.pdf,https://doi.org/10.1108/SASBE-03-2021-0036,
The Effects of Virtual Avatar Visibility on Pointing Interpretation by Observers in 3D Environments,"Avatars are often used to provide representations of users in 3D environments, such as desktop games or VR applications. While full-body avatars are often sought to be used in applications, low visibility avatars (i.e., head and hands) are often used in a variety of contexts, either as intentional design choices, for simplicity in contexts where full-body avatars are not needed, or due to external limitations. Avatar style can also vary from more simplistic and abstract to highly realistic depending on application context and user choices. We present the results of two desktop experiments that examine avatar visibility, style, and observer view on accuracy in a pointing interpretation task. Significant effects of visibility were found, with effects varying between horizontal and vertical components of error, and error amounts not always worsening as a result of lowering visibility. Error due to avatar visibility was much smaller than error resulting from avatar style or observer view. Our findings suggest that humans are reasonably able to understand pointing gestures with a limited observable body.",IEEE International Symposium on Mixed and Augmented Reality,Conference,2021,to appear in ISMAR 2021,"Brett Benda, Eric D. Ragan",TheEffectsofVirtualAvatarVisibilityonPointingInterpretation.pdf,,
